{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, Input, Dense, Reshape, Conv2DTranspose,\\\n",
    "    Activation, BatchNormalization, ReLU, Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from tensorflow.keras.utils import Sequence\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUS:  1\n"
     ]
    }
   ],
   "source": [
    "devices=tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"GPUS: \", len(devices))\n",
    "tf.config.experimental.set_memory_growth(devices[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "\n",
    "  def __init__(self, base_dir,base_dir2, output_size, shuffle=False, batch_size=10):\n",
    "    self.base_dir = base_dir\n",
    "    self.base_dir2 = base_dir2\n",
    "    self.output_size = output_size\n",
    "    self.shuffle = shuffle\n",
    "    self.batch_size = batch_size\n",
    "    self.all_x = os.listdir(base_dir)\n",
    "    self.all_y = os.listdir(base_dir2)\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indices = np.arange(len(self.all_x))\n",
    "    if self.shuffle:\n",
    "      np.random.shuffle(self.indices)\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(len(self.all_x) / self.batch_size)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    X = np.empty((self.batch_size, *self.output_size, 3))\n",
    "    Y = np.empty((self.batch_size, *self.output_size, 3))\n",
    "\n",
    "    indices = self.indices[idx*(self.batch_size): (idx+1)*(self.batch_size)]\n",
    "    \n",
    "\n",
    "    for i,j in enumerate(indices):\n",
    "      img_path = os.path.join(self.base_dir,self.all_x[j])\n",
    "      img_path2 = os.path.join(self.base_dir2,self.all_y[j])\n",
    "        \n",
    "      img  = cv2.imread(img_path)\n",
    "      img= cv2.resize(cv2.cvtColor(img,cv2.COLOR_BGR2RGB),self.output_size)\n",
    "      img2 = cv2.imread(img_path2)\n",
    "      img2= cv2.resize(cv2.cvtColor(img2,cv2.COLOR_BGR2RGB),self.output_size)\n",
    "#       print(img_path,img_path2)\n",
    "\n",
    "      X[i,] = img\n",
    "      Y[i,] = img2\n",
    "    X= X.astype('float32')/255\n",
    "    Y= Y.astype('float32')/255\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "  fig,axes = plt.subplots(1,10,figsize=(20,20))\n",
    "  axes=axes.flatten()\n",
    "  for img,ax in zip(images_arr,axes):\n",
    "    img=img.astype(np.uint8)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataGenerator('data/train_x/train_x','data/train_y/train_y',(64,64), batch_size=128, shuffle=False)\n",
    "test  = DataGenerator('data/test_x/test_x','data/test_y/test_y',(64,64), batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=train[32]\n",
    "plotImages(xx)\n",
    "plotImages(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_operation(x, filters, kernel_size, strides=2):\n",
    "   x = Conv2D(filters=filters,\n",
    "              kernel_size=kernel_size,\n",
    "              strides=strides,\n",
    "              padding='same')(x)\n",
    "   x = BatchNormalization()(x)\n",
    "   x = ReLU()(x)\n",
    "   return x\n",
    "\n",
    "def conv_transpose_operation(x, filters, kernel_size):\n",
    "   x = Conv2DTranspose(filters=filters,\n",
    "                       kernel_size=kernel_size,\n",
    "                       strides=2,\n",
    "                       padding='same')(x)\n",
    "   x = BatchNormalization()(x)\n",
    "   x = ReLU()(x)\n",
    "   return x\n",
    "\n",
    "def deblurring_autoencoder():\n",
    "   dae_inputs = Input(shape=(64,64,3), name='dae_input')\n",
    "   conv_block1 = conv_operation(dae_inputs, 32, 3)\n",
    "   conv_block2 = conv_operation(conv_block1, 64, 3)\n",
    "   conv_block3 = conv_operation(conv_block2, 128, 3)\n",
    "   conv_block4 = conv_operation(conv_block3, 256, 3)\n",
    "   \n",
    "   conv_block5 = conv_operation(conv_block4, 256, 3, 1)\n",
    "\n",
    "   deconv_block1 = conv_transpose_operation(conv_block5, 256,3)\n",
    "   merge1 = Concatenate()([conv_block3,deconv_block1])\n",
    "   deconv_block2 = conv_transpose_operation(merge1, 128, 3)\n",
    "   merge2 = Concatenate()([deconv_block2, conv_block2])\n",
    "   deconv_block3 = conv_transpose_operation(merge2, 64, 3)\n",
    "   merge3 = Concatenate()([deconv_block3, conv_block1])\n",
    "   deconv_block4 = conv_transpose_operation(merge3, 32, 3)\n",
    "\n",
    "   final_deconv = Conv2DTranspose(filters=3, kernel_size=3,padding='same')(deconv_block4)\n",
    "\n",
    "#    dae_outputs = Activation('sigmoid', name='dae_output')(final_deconv)\n",
    "   \n",
    "   return Model(dae_inputs, final_deconv, name='dae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= deblurring_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dae\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dae_input (InputLayer)          [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   896         dae_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 64)   18496       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 16, 16, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 128)    73856       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 8, 128)    512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 8, 8, 128)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 256)    295168      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, 4, 256)    1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 4, 4, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 256)    590080      re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 256)    1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 4, 4, 256)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 8, 8, 256)    590080      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 256)    1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 8, 8, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 384)    0           re_lu_2[0][0]                    \n",
      "                                                                 re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 128)  442496      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 16, 16, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 192)  0           re_lu_6[0][0]                    \n",
      "                                                                 re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   110656      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 96)   0           re_lu_7[0][0]                    \n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 32)   27680       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 32)   128         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 64, 64, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 3)    867         re_lu_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,155,139\n",
      "Trainable params: 2,152,707\n",
      "Non-trainable params: 2,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks=[\n",
    "    ModelCheckpoint('deblur_my_shit.h5',verbose=1,save_best_only=True,save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 78 steps\n",
      "Epoch 1/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0793WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 21s 264ms/step - loss: 0.0108 - mae: 0.0791\n",
      "Epoch 2/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0754WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 22s 278ms/step - loss: 0.0101 - mae: 0.0763\n",
      "Epoch 3/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 21s 271ms/step - loss: 0.0097 - mae: 0.0746\n",
      "Epoch 4/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0732WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 21s 271ms/step - loss: 0.0092 - mae: 0.0731\n",
      "Epoch 5/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0716WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 21s 272ms/step - loss: 0.0089 - mae: 0.0717\n",
      "Epoch 6/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0706WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 21s 273ms/step - loss: 0.0087 - mae: 0.0705\n",
      "Epoch 7/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0687WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 21s 273ms/step - loss: 0.0082 - mae: 0.0689\n",
      "Epoch 8/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 22s 277ms/step - loss: 0.0079 - mae: 0.0676\n",
      "Epoch 9/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0662WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 22s 280ms/step - loss: 0.0076 - mae: 0.0660\n",
      "Epoch 10/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0653WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 22s 278ms/step - loss: 0.0073 - mae: 0.0650\n",
      "Epoch 11/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0637WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 22s 278ms/step - loss: 0.0071 - mae: 0.0638\n",
      "Epoch 12/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0628WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 22s 281ms/step - loss: 0.0068 - mae: 0.0625\n",
      "Epoch 13/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 23s 291ms/step - loss: 0.0063 - mae: 0.0597\n",
      "Epoch 14/20\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "78/78 [==============================] - 22s 280ms/step - loss: 0.0066 - mae: 0.0615\n",
      "Epoch 15/20\n",
      "34/78 [============>.................] - ETA: 12s - loss: 0.0060 - mae: 0.0579"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
